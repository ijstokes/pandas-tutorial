{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Compute\n",
    "\n",
    "We oftentimes want to interact with other libraries and have them handle pandas objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='data/pydata-ecosystem.png',height=1024,width=1024) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We are going to look at some interactions with:\n",
    "\n",
    "- ``scikit-learn``\n",
    "- ``statsmodels``\n",
    "- ``numba`` & ``cython``\n",
    "- ``dask``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_rows = 8\n",
    "pd.options.display.max_columns = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scikit-Learn\n",
    "\n",
    "http://scikit-learn.org/stable/documentation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn's algorithms all deal with numpy arrays. typically:\n",
    "\n",
    "- data munging in pandas\n",
    "- pass numpy array to an Estimator\n",
    "- wrap result in a DataFrame or Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import california_housing\n",
    "data = california_housing.fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "y = pd.Series(data.target)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = dict(\n",
    "    max_features=np.arange(2, 8),\n",
    "    max_depth=[2, 4],\n",
    "    min_samples_split=[5, 10, 15, 20],\n",
    ")\n",
    "rfc = RandomForestRegressor(n_estimators=10)\n",
    "gs = GridSearchCV(rfc, param_grid, cv=5, n_jobs=-1)\n",
    "gs.fit(X.values, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "scores = gs.grid_scores_\n",
    "scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def unpack_grid_scores(scores):\n",
    "    rows = []\n",
    "    params = sorted(scores[0].parameters)\n",
    "    for row in scores:\n",
    "        mean = row.mean_validation_score\n",
    "        std = row.cv_validation_scores.std()\n",
    "        rows.append([mean, std] + [row.parameters[k] for k in params])\n",
    "    return pd.DataFrame(rows, columns=['mean_', 'std_'] + params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = unpack_grid_scores(gs.grid_scores_)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "(scores\n",
    "       .pipe((sns.factorplot,'data'), x='max_features', y='mean_', hue='max_depth', col='min_samples_split')\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "s = pd.Series(gs.best_estimator_.feature_importances_,index=X.columns)\n",
    "(s.sort_values()\n",
    "  .plot\n",
    "  .barh(figsize=(5,8))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Statsmodels\n",
    "\n",
    "http://statsmodels.sourceforge.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "statsmodels.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# created in 4. Tidy Data\n",
    "df = pd.read_hdf('data/games.hdf','df')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['home_win'] = df.home_win.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f ='home_win ~ home_strength + away_strength + home_rest + away_rest'\n",
    "res = (sm\n",
    "         .Logit\n",
    "         .from_formula(f, df)\n",
    "         .fit()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df.assign(rest_difference=df.home_rest - df.away_rest,\n",
    "                spread=df.home_points - df.away_points)\n",
    "\n",
    "f = 'spread ~ home_strength + away_strength + rest_difference'\n",
    "res = (sm\n",
    "         .OLS\n",
    "         .from_formula(f, df2)\n",
    "         .fit()\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Numba & Cython\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/enhancingperf.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import cython\n",
    "%load_ext cython\n",
    "\n",
    "np.random.seed(1234)\n",
    "pd.set_option('max_row',12)\n",
    "s = Series(np.random.randn(1e5))\n",
    "com = 20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def python(s):\n",
    "    output = Series(index=range(len(s)))\n",
    "\n",
    "    alpha = 1. / (1. + com)\n",
    "    old_weight = 1.0\n",
    "    new_weight = 1.0\n",
    "    weighted_avg = s[0]\n",
    "    output[0] = weighted_avg\n",
    "    \n",
    "    for i in range(1,len(s)):\n",
    "        v = s[i]\n",
    "        old_weight *= (1-alpha)\n",
    "        weighted_avg = ((old_weight * weighted_avg) + \n",
    "                        (new_weight * v)) / (old_weight + new_weight)\n",
    "        old_weight += new_weight\n",
    "        output[i] = weighted_avg\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "cimport cython\n",
    "@cython.wraparound(False)\n",
    "@cython.boundscheck(False)\n",
    "def _cython(double[:] arr, double com, double[:] output):\n",
    "    cdef:\n",
    "        double alpha, old_weight, new_weight, weighted_avg, v\n",
    "        int i\n",
    "    \n",
    "    alpha = 1. / (1. + com)\n",
    "    old_weight = 1.0\n",
    "    new_weight = 1.0\n",
    "    weighted_avg = arr[0]\n",
    "    output[0] = weighted_avg\n",
    "    \n",
    "    for i in range(1,arr.shape[0]):\n",
    "        v = arr[i]\n",
    "        old_weight *= (1-alpha)\n",
    "        weighted_avg = ((old_weight * weighted_avg) + \n",
    "                        (new_weight * v)) / (old_weight + new_weight)\n",
    "        old_weight += new_weight\n",
    "        output[i] = weighted_avg\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def cython1(s):\n",
    "    output = np.empty(len(s),dtype='float64')\n",
    "    _cython(s.values, com, output)\n",
    "    return Series(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def cython2(s):\n",
    "    return pd.ewma(s,com=com,adjust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def _numba(arr, output):\n",
    "    alpha = 1. / (1. + com)\n",
    "    old_weight = 1.0\n",
    "    new_weight = 1.0\n",
    "    weighted_avg = arr[0]\n",
    "    output[0] = weighted_avg\n",
    "    \n",
    "    for i in range(1,arr.shape[0]):\n",
    "        v = arr[i]\n",
    "        old_weight *= (1-alpha)\n",
    "        weighted_avg = ((old_weight * weighted_avg) + \n",
    "                        (new_weight * v)) / (old_weight + new_weight)\n",
    "        old_weight += new_weight\n",
    "        output[i] = weighted_avg\n",
    "    \n",
    "\n",
    "def numba(s):\n",
    " \n",
    "    output = np.empty(len(s),dtype='float64')\n",
    "    _numba(s.values, output)\n",
    "    return Series(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "result1 = python(s)\n",
    "result2 = cython1(s)\n",
    "result3 = cython2(s)\n",
    "result4 = numba(s)\n",
    "result1.equals(\n",
    "    result2) and result1.equals(\n",
    "    result3) and result1.equals(\n",
    "    result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%timeit python(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%timeit cython1(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%timeit cython2(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%timeit numba(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dask\n",
    "\n",
    "https://dask.readthedocs.org/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask import threaded, multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "N = int(1e7)\n",
    "df = DataFrame({'key' : np.random.randint(0,1000,size=N), \n",
    "                'value' : np.random.randn(N)})\n",
    "ddf = dd.from_pandas(df, npartitions=8)\n",
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%timeit df.groupby('key').value.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%timeit ddf.groupby('key').value.sum().compute(get=threaded.get)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
